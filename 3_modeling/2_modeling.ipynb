{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "train_data=pd.read_csv('../data/final_data/train_data.csv',index_col=0)\n",
    "\n",
    "test_data=pd.read_csv('../data/final_data/test_data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from mlxtend.regressor import StackingCVRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_ridge=KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "\n",
    "gradient_boosting = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "random_forest=RandomForestRegressor(n_estimators=3000)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "\n",
    "stack_gen = StackingCVRegressor(regressors=(kernel_ridge, gradient_boosting,random_forest, model_xgb, model_lgb),\n",
    "                                meta_regressor=model_lgb,\n",
    "                                use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "ssc = StandardScaler()\n",
    "rbs = RobustScaler()\n",
    "\n",
    "train_data_ssc =ssc.fit_transform(train_data.iloc[:,4:])\n",
    "test_data_ssc = ssc.transform(test_data.iloc[:,4:])\n",
    "train_target = train_data.iloc[:,:4]\n",
    "\n",
    "train_data_rbs =rbs.fit_transform(train_data.iloc[:,4:])\n",
    "test_data_rbs = rbs.transform(test_data.iloc[:,4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "kfold = KFold()\n",
    "for i in range(4):\n",
    "    for model in [kernel_ridge, gradient_boosting,random_forest, model_xgb, model_lgb,stack_gen]:\n",
    "        result=cross_val_score(model,train_data_ssc,train_target.iloc[:,i],scoring='neg_mean_absolute_error')\n",
    "        print(str(model).split('(')[0])\n",
    "        print(np.mean(result)*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "vot_model = VotingRegressor(\n",
    "    [('m1',kernel_ridge),\n",
    "     ('m2',model_xgb),\n",
    "     ('m3',model_lgb),\n",
    "     ('m4',gradient_boosting)]   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "kfold = KFold()\n",
    "for i in range(4):\n",
    "    for model in [vot_model]:\n",
    "        result=cross_val_score(model,train_data_ssc,train_target.iloc[:,i],scoring='neg_mean_absolute_error')\n",
    "        print(str(model).split('(')[0])\n",
    "        print(np.mean(result)*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vot_model1 = VotingRegressor(\n",
    "    [('m4',kernel_ridge),\n",
    "     ('m1',model_xgb),\n",
    "     ('m2',gradient_boosting),\n",
    "     ('m3',model_lgb)]\n",
    "    \n",
    ")\n",
    "vot_model2 = VotingRegressor(\n",
    "    [('m1',kernel_ridge),\n",
    "     ('m2',model_xgb),\n",
    "     ('m3',model_lgb),\n",
    "     ('m4',gradient_boosting)]\n",
    "    \n",
    ")\n",
    "vot_model3 = VotingRegressor(\n",
    "    [('m1',kernel_ridge),\n",
    "     ('m2',model_xgb),\n",
    "     ('m3',model_lgb),\n",
    "     ('m4',gradient_boosting)]    \n",
    ")\n",
    "vot_model4 = VotingRegressor(\n",
    "    [('m1',kernel_ridge),\n",
    "     ('m2',model_xgb),\n",
    "     ('m3',model_lgb),\n",
    "     ('m4',gradient_boosting)]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_a = train_target.iloc[:,0]\n",
    "train_target_b = train_target.iloc[:,1]\n",
    "train_target_c = train_target.iloc[:,2]\n",
    "train_target_d = train_target.iloc[:,3]\n",
    "\n",
    "vot_model1.fit(train_data_ssc,train_target_a)\n",
    "vot_model2.fit(train_data_ssc,train_target_b)\n",
    "vot_model3.fit(train_data_ssc,train_target_c)\n",
    "vot_model4.fit(train_data_ssc,train_target_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_raw=pd.read_csv('../data/raw_data/sample_submission.csv')\n",
    "\n",
    "sample_submission_raw.iloc[:,1] =vot_model1.predict(test_data_ssc)\n",
    "sample_submission_raw.iloc[:,2] =vot_model2.predict(test_data_ssc)\n",
    "sample_submission_raw.iloc[:,3] =vot_model3.predict(test_data_ssc)\n",
    "sample_submission_raw.iloc[:,4] =vot_model4.predict(test_data_ssc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_raw.to_csv('voting_withboosts.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.8989104582"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
